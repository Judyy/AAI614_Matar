{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Judyy/AAI614_Matar/blob/main/Notebook4_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DY6r9WXybbYn"
      },
      "source": [
        "# AAI614: Data Science & its Applications\n",
        "\n",
        "*Notebook 4.1: Graph Analytics with cuGraph and TIGER*\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The study of network robustness is critical to the understanding of complex interconnected systems. For example, consider an example of a power grid network that is susceptible to both natural failures and targeted attacks. A natural failure occurs when a single power substation fails due to erosion of parts or natural disasters. However, when one substation fails, additional load is routed to alternative substations, potentially causing a series of cascading failures. Not all failures originate from natural causes, some come from targeted attacks, such as enemy states hacking into the grid to sabotage key equipment to maximally damage the operations of the electrical grid. A natural counterpart to network robustness is vulnerability, defined as measure of a network‚Äôs susceptibility to the dissemination of entities across the network, such as how quickly a virus spreads across a computer network.\n",
        "\n",
        "In this lab, we show how to use [cuGraph](https://github.com/rapidsai/cugraph) and [TIGER](https://github.com/safreita1/TIGER) to conduct state-of-the-art GPU accelerated graph vulnerability and robustness analysis. Specifically, we will look at how to:\n",
        "\n",
        "- *Quantify network vulnerability and robustness* (**Part 1**),\n",
        "- *Simulate network attacks and cascading failures on networks* (**Part 2**)\n",
        "- *Regulate the dissemination of computer virues on a network* (**Part 3**)\n",
        "\n",
        "Lab Source: **NVIDIA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m07IHxfBuBp7"
      },
      "source": [
        "## Setup\n",
        "Lets begin by installing the following 2 libraries:\n",
        "\n",
        "1.   Graph vulnerability and robustness analysis library: [TIGER](https://github.com/safreita1/TIGER)\n",
        "2.   GPU acceleration library: [CuPy](https://github.com/cupy/cupy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0w_bThcZtlX3",
        "outputId": "42b8d4b9-f1e0-48a4-9141-4ca0be31a662"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting graph-tiger\n",
            "  Downloading graph-tiger-0.2.5.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: graph-tiger\n",
            "  Building wheel for graph-tiger (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for graph-tiger: filename=graph_tiger-0.2.5-py3-none-any.whl size=38728 sha256=d07737f55fe49ea001ca2a2f6c2f84ad2749092deaedf5fcbb0803b69ce1c108\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/52/6f/dcd520fee364f2f389ff847b14aae7f8580851cd9e52459d0d\n",
            "Successfully built graph-tiger\n",
            "Installing collected packages: graph-tiger\n",
            "Successfully installed graph-tiger-0.2.5\n"
          ]
        }
      ],
      "source": [
        "pip install graph-tiger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KkbW2e1JyDLc",
        "outputId": "a237e661-0c5e-4018-9e7b-35ede7afb442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'rapidsai-csp-utils' already exists and is not an empty directory.\n",
            "PLEASE READ FOR 21.06\n",
            "********************************************************************************************************\n",
            "Another release, another script change.  We had to revise the script, which now:\n",
            "1. Does a more comprehensive install\n",
            "2. Includes BlazingSQL\n",
            "3. is far easier for everyone to understand and maintain\n",
            "\n",
            "The script will require you to add these 5 cells to your notebook.  We have also created a new startup template: \n",
            "https://colab.research.google.com/drive/1TAAi_szMfWqRfHVfjGSqnGVLr_ztzUM9?usp=sharing\n",
            "\n",
            "CHANGES T\n",
            "CELL 1:\n",
            "    # This get the RAPIDS-Colab install files and test check your GPU.  Run cells 1 and 2 only.\n",
            "    # Please read the output of this cell.  If your Colab Instance is not RAPIDS compatible, it will warn you and give you remediation steps.\n",
            "    !git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
            "    !python rapidsai-csp-utils/colab/env-check.py\n",
            "\n",
            "CELL 2:\n",
            "    # This will update the Colab environment and restart the kernel.\n",
            "    !bash rapidsai-csp-utils/colab/update_gcc.sh\n",
            "    import os\n",
            "    os._exit(00)\n",
            "\n",
            "CELL 3:\n",
            "    ## Installing CondaColab.  This will restart your kernel again\n",
            "    import condacolab\n",
            "    condacolab.install()\n",
            "\n",
            "CELL 4:\n",
            "    import condacolab\n",
            "    condacolab.check()\n",
            "\n",
            "CELL 5:\n",
            "    # Installing RAPIDS is now 'python rapidsai-csp-utils/colab/install_rapids.py <release> <packages>'\n",
            "    # The <release> options are 'stable' and 'nightly'.  Leaving it blank or adding any other words will default to stable.\n",
            "    # The <packages> option are default blank or 'core'.  By default, we install RAPIDSAI and BlazingSQL.  The 'core' option will install only RAPIDSAI and not include BlazingSQL, \n",
            "    !python rapidsai-csp-utils/colab/install_rapids.py nightly\n",
            "    import os\n",
            "    os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n",
            "    os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'\n",
            "    os.environ['CONDA_PREFIX'] = '/usr/local'\n",
            "\n",
            "********************************************************************************************************\n",
            "\n",
            "Enjoy using RAPIDS!  If you have any issues with or suggestions for RAPIDSAI on Colab, please create a issue on https://github.com/rapidsai/rapidsai-csp-utils/issues/new.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "'/usr/local/lib/python3.7/dist-packages' is not in list",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-fb7ed10361b8>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdist_package_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/usr/local/lib/python3.7/dist-packages'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdist_package_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'/usr/local/lib/python3.7/site-packages'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdist_package_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: '/usr/local/lib/python3.7/dist-packages' is not in list"
          ]
        }
      ],
      "source": [
        "# Install RAPIDS\n",
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!bash rapidsai-csp-utils/colab/rapids-colab.sh stable\n",
        "\n",
        "import sys, os\n",
        "\n",
        "dist_package_index = sys.path.index('/usr/local/lib/python3.7/dist-packages')\n",
        "sys.path = sys.path[:dist_package_index] + ['/usr/local/lib/python3.7/site-packages'] + sys.path[dist_package_index:]\n",
        "sys.path\n",
        "exec(open('rapidsai-csp-utils/colab/update_modules.py').read(), globals())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!python rapidsai-csp-utils/colab/env-check.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgTqGmqCoguK",
        "outputId": "459e481d-cc9c-43fc-95ec-7bf814b2e738"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'rapidsai-csp-utils' already exists and is not an empty directory.\n",
            "Collecting pynvml\n",
            "  Downloading pynvml-11.5.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Downloading pynvml-11.5.3-py3-none-any.whl (53 kB)\n",
            "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 53.1/53.1 kB 2.7 MB/s eta 0:00:00\n",
            "Installing collected packages: pynvml\n",
            "Successfully installed pynvml-11.5.3\n",
            "***********************************************************************\n",
            "Woo! Your instance has the right kind of GPU, a Tesla T4!\n",
            "We will now install RAPIDS via pip!  Please stand by, should be quick...\n",
            "***********************************************************************\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fY4Lymv-x7G0"
      },
      "source": [
        "That's it! Now we can run a variety of GPU acclerated graph mining algorithms.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash rapidsai-csp-utils/colab/update_gcc.sh\n",
        "import os\n",
        "os._exit(00)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjeiJpMUosAB",
        "outputId": "c052b872-bae7-42fc-a67b-e7617d6dc45a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updating your Colab environment.  This will restart your kernel.  Don't Panic!\n",
            "Found existing installation: cupy-cuda12x 12.2.0\n",
            "Uninstalling cupy-cuda12x-12.2.0:\n",
            "  Successfully uninstalled cupy-cuda12x-12.2.0\n",
            "restarting Colab...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Installing CondaColab.  This will restart your kernel again\n",
        "import condacolab\n",
        "condacolab.install()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUsu4Au8o0PW",
        "outputId": "2943dff0-e4b2-4447-b7fa-ee930ab804a5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è¨ Downloading https://github.com/conda-forge/miniforge/releases/download/23.11.0-0/Mambaforge-23.11.0-0-Linux-x86_64.sh...\n",
            "üì¶ Installing...\n",
            "üìå Adjusting configuration...\n",
            "ü©π Patching environment...\n",
            "‚è≤ Done in 0:00:15\n",
            "üîÅ Restarting kernel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import condacolab\n",
        "condacolab.check()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNzsII10o7Hs",
        "outputId": "786b0fef-efe1-49d4-8159-ff7c67e967cc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ú®üç∞‚ú® Everything looks OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing RAPIDS is now 'python rapidsai-csp-utils/colab/install_rapids.py <release> <packages>'\n",
        "# The <release> options are 'stable' and 'nightly'.  Leaving it blank or adding any other words will default to stable.\n",
        "# The <packages> option are default blank or 'core'.  By default, we install RAPIDSAI and BlazingSQL.  The 'core' option will install only RAPIDSAI and not include BlazingSQL,\n",
        "!python rapidsai-csp-utils/colab/install_rapids.py nightly\n",
        "import os\n",
        "os.environ['NUMBAPRO_NVVM'] = '/usr/local/cuda/nvvm/lib64/libnvvm.so'\n",
        "os.environ['NUMBAPRO_LIBDEVICE'] = '/usr/local/cuda/nvvm/libdevice/'\n",
        "os.environ['CONDA_PREFIX'] = '/usr/local'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNjF7TgHo_sp",
        "outputId": "d0b2b734-56cc-4127-c3c6-5fd2dccede7f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pynvml\n",
            "  Using cached pynvml-11.5.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Using cached pynvml-11.5.3-py3-none-any.whl (53 kB)\n",
            "Installing collected packages: pynvml\n",
            "Successfully installed pynvml-11.5.3\n",
            "Found existing installation: cffi 1.16.0\n",
            "Uninstalling cffi-1.16.0:\n",
            "  Successfully uninstalled cffi-1.16.0\n",
            "WARNING: Skipping cryptography as it is not installed.\n",
            "Collecting cffi==1.15.0\n",
            "  Downloading cffi-1.15.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/site-packages (from cffi==1.15.0) (2.21)\n",
            "Downloading cffi-1.15.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (446 kB)\n",
            "   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 446.3/446.3 kB 9.8 MB/s eta 0:00:00\n",
            "Installing collected packages: cffi\n",
            "Successfully installed cffi-1.15.0\n",
            "Installing RAPIDS Nightly 24.04\n",
            "Starting the RAPIDS install on Colab.  This will take about 15 minutes.\n",
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - mamba\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    archspec-0.2.3             |     pyhd8ed1ab_0          48 KB  conda-forge\n",
            "    ca-certificates-2024.8.30  |       hbcca054_0         155 KB  conda-forge\n",
            "    certifi-2024.8.30          |     pyhd8ed1ab_0         160 KB  conda-forge\n",
            "    conda-24.7.1               |  py310hff52083_0         940 KB  conda-forge\n",
            "    fmt-10.2.1                 |       h00ab1b0_0         189 KB  conda-forge\n",
            "    frozendict-2.4.6           |  py310ha75aee5_0          48 KB  conda-forge\n",
            "    libcurl-8.8.0              |       hca28451_0         396 KB  conda-forge\n",
            "    libgcc-14.2.0              |       h77fa898_1         829 KB  conda-forge\n",
            "    libgcc-ng-14.2.0           |       h69a702a_1          53 KB  conda-forge\n",
            "    libgomp-14.2.0             |       h77fa898_1         450 KB  conda-forge\n",
            "    libmamba-1.5.8             |       had39da4_0         1.6 MB  conda-forge\n",
            "    libmambapy-1.5.8           |  py310h39ff949_0         302 KB  conda-forge\n",
            "    mamba-1.5.8                |  py310h51d5547_0          51 KB  conda-forge\n",
            "    openssl-3.4.0              |       hb9d3cd8_0         2.8 MB  conda-forge\n",
            "    zstandard-0.23.0           |  py310ha39cb0e_1         399 KB  conda-forge\n",
            "    zstd-1.5.6                 |       ha6fb4c9_0         542 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         8.9 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  frozendict         conda-forge/linux-64::frozendict-2.4.6-py310ha75aee5_0\n",
            "  libgcc             conda-forge/linux-64::libgcc-14.2.0-h77fa898_1\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  archspec                               0.2.2-pyhd8ed1ab_0 --> 0.2.3-pyhd8ed1ab_0\n",
            "  ca-certificates                     2023.11.17-hbcca054_0 --> 2024.8.30-hbcca054_0\n",
            "  certifi                           2023.11.17-pyhd8ed1ab_0 --> 2024.8.30-pyhd8ed1ab_0\n",
            "  conda                             23.11.0-py310hff52083_1 --> 24.7.1-py310hff52083_0\n",
            "  fmt                                     10.1.1-h00ab1b0_1 --> 10.2.1-h00ab1b0_0\n",
            "  libcurl                                  8.5.0-hca28451_0 --> 8.8.0-hca28451_0\n",
            "  libgcc-ng                               13.2.0-h807b86a_3 --> 14.2.0-h69a702a_1\n",
            "  libgomp                                 13.2.0-h807b86a_3 --> 14.2.0-h77fa898_1\n",
            "  libmamba                                 1.5.5-had39da4_0 --> 1.5.8-had39da4_0\n",
            "  libmambapy                          1.5.5-py310h39ff949_0 --> 1.5.8-py310h39ff949_0\n",
            "  mamba                               1.5.5-py310h51d5547_0 --> 1.5.8-py310h51d5547_0\n",
            "  openssl                                  3.2.0-hd590300_1 --> 3.4.0-hb9d3cd8_0\n",
            "  zstandard                          0.22.0-py310h1275a96_0 --> 0.23.0-py310ha39cb0e_1\n",
            "  zstd                                     1.5.5-hfc55251_0 --> 1.5.6-ha6fb4c9_0\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages: ...working... done\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "warning  libmamba Could not parse mod/etag header\n",
            "warning  libmamba Could not parse mod/etag header\n",
            "\n",
            "Looking for: ['python=3.10', 'cuda-version=12.0', 'rapids=24.04', 'llvmlite', 'gcsfs', 'openssl', 'dask-sql']\n",
            "\n",
            "\n",
            "Pinned packages:\n",
            "  - python 3.10.*\n",
            "  - python_abi 3.10.* *cp310*\n",
            "  - cuda-version 12.*\n",
            "\n",
            "\n",
            "Could not solve for environment specs\n",
            "The following package could not be installed\n",
            "‚îî‚îÄ rapids 24.04**  does not exist (perhaps a typo or a missing channel).\n",
            "RAPIDS conda installation complete.  Updating Colab's libraries...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -qO- https://raw.githubusercontent.com/rapidsai/rapidsai-csp-utils/main/colab/install_rapids.sh | bash -s -- 22.12\n"
      ],
      "metadata": {
        "id": "xntak2j8qPBl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4FE0CuqqT9N",
        "outputId": "28af56f8-39cc-4490-d138-703e4bd47f3c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JBQLhrOCYFn"
      },
      "source": [
        "## Part 1: Quantifing network vulnerability and robustness\n",
        "\n",
        "While CPU calculations work well for sparse graphs, GPU acceleration significantly speeds-up analysis for dense graphs. To see this, lets run the code below that measures the robustness of a Barab√°si Albert (BA) graph at varying levels of density (i.e., number of edges per node)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QhLLxqeJCV6P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "outputId": "fb36ace4-b566-4a2e-c7e6-cd230af0c574"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'stopit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-aac2111d1b94>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgraph_tiger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_measure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgraph_tiger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraphs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/graph_tiger/measures.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstopit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseterr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'stopit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "from graph_tiger.measures import run_measure\n",
        "from graph_tiger.graphs import graph_loader\n",
        "\n",
        "# controls graph density by varying the number of non-zeroes per row (i.e., number of edges per node in graph)\n",
        "nnz_per_row = list(range(50, 501, 50))\n",
        "\n",
        "cpu_times = []\n",
        "gpu_times = []\n",
        "for nnz in tqdm(nnz_per_row):\n",
        "  graph = graph_loader(graph_type='BA', n=1000, m=nnz, seed=1)\n",
        "\n",
        "  start_cpu = time.time()\n",
        "  robustness_index = run_measure(graph, measure='average_vertex_betweenness', k=int(0.05 * len(graph)))\n",
        "  end_cpu = time.time()\n",
        "\n",
        "  start_gpu = time.time()\n",
        "  robustness_index = run_measure(graph, measure='average_vertex_betweenness', k=12, use_gpu=True)  # ****** Replace with cuGraph version: https://docs.rapids.ai/api/cugraph/stable/api.html#module-cugraph.centrality.betweenness_centrality ******\n",
        "  end_gpu = time.time()\n",
        "\n",
        "\n",
        "  cpu_times.append(round(end_cpu - start_cpu, 2))\n",
        "  gpu_times.append(round(end_gpu - start_gpu, 2))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feSLclFDI4c5"
      },
      "source": [
        "Now lets plot the results (lower is better)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L00rAHJpCV03"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(nnz_per_row, cpu_times, label='CPU')\n",
        "plt.plot(nnz_per_row, gpu_times, label='GPU')\n",
        "plt.xlabel('Number of edges per node (NNZ)')\n",
        "plt.ylabel('Time (seconds)')\n",
        "plt.title('Measuring Graph Robustness Runtime (CPU vs. GPU)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X58wipWGyaJd"
      },
      "source": [
        "## Part 2. Simulating Cascading Failures in U.S. Electrical Grid\n",
        "Cascading failures often arise as a result of natural failures or targeted attacks in a network. There are 3 main processes governing the network simulation:\n",
        "\n",
        "- the **capacity** of each node (<img src=\"https://render.githubusercontent.com/render/math?math=c_v\">) in the network, e.g., power substation capacity.\n",
        "\n",
        "- the **load** of each node (<img src=\"https://render.githubusercontent.com/render/math?math=l_v\">) in the network, e.g., power substation load level\n",
        "\n",
        "- network **redundancy** (*r*) representing the amount of reserve capacity present in the network i.e., auxiliary support systems.\n",
        "\n",
        "When a node is attacked it becomes \"overloaded\", causing it to fail and requiring the load be distributed to its neighbors. When defending a node, we increase it‚Äôs capacity to protect against attacks. With just these 3 parameters, we can setup a cascading failure simulation. Below, we show how to load a graph representing the U.S. electrical grid and setup the simulation parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaOR8IqVN78X"
      },
      "outputs": [],
      "source": [
        "from graph_tiger.graphs import graph_loader\n",
        "\n",
        "graph = graph_loader('electrical')\n",
        "\n",
        "params = {\n",
        "   'runs': 1,  # number of times to run the simulation\n",
        "   'steps': 100,  # number of time steps to run each simulation\n",
        "   'seed': 1,  # for repoducibility\n",
        "\n",
        "   'l': 0.8,  # network load [0, 1]\n",
        "   'r': 0.2,  # network redundancey [0, 1]\n",
        "   'c': int(0.1 * len(graph)),  # load capacity approximation\n",
        "\n",
        "   'robust_measure': 'largest_connected_component',  # measure of network health\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEUFDjjYPJIX"
      },
      "source": [
        "### Setting up a Targeted Attack\n",
        "To run the attack we just have to modify a few simulation parameters. We set the attack to remove 30 nodes in the graph (e.g., power grid substations) with highest degree centrality \"id_node\". As you can imagine, there are many different strategies that can be used to attack the grid, however, by selecting degree centrality we can find \"central\" nodes in the network with many power lines (edges) connected to the substations (nodes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIxAypOhN3vm"
      },
      "outputs": [],
      "source": [
        "params.update({\n",
        "   'k_a': 30,  # number of nodes to attack\n",
        "   'attack': 'id_node',  # attack strategy\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfJ4xq2jPPCX"
      },
      "source": [
        "Now lets run the simulation and plot the results!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgfVtPu2PPZj"
      },
      "outputs": [],
      "source": [
        "from graph_tiger.cascading import Cascading\n",
        "\n",
        "cascading = Cascading(graph, **params)\n",
        "results = cascading.run_simulation()\n",
        "\n",
        "cascading.plot_results(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVhxmxWCdUo4"
      },
      "source": [
        "### 1. Collapsing a network\n",
        "\n",
        "Now try modifying the code to find the minimal attack necessary to collapse the electrical grid. To do this, plot the \"health\" of the network as measured by the robustness measure (i.e., \"largest_connected_component\") at the end of each simulation, against the attack strength (\"k_a\").\n",
        "\n",
        "**Hint:** electrical networks are fragile to targeted attacks, try removing just a few nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJ5nvT4SdU98"
      },
      "outputs": [],
      "source": [
        "sim_results =[]\n",
        "\n",
        "params['attack'] = 'id_node'\n",
        "attack_strengths = list(range(0, 6, 1))\n",
        "\n",
        "for k_a in tqdm(attack_strengths):\n",
        "  params['k_a'] = k_a\n",
        "\n",
        "  cascading = Cascading(graph, **params)\n",
        "  results = cascading.run_simulation()\n",
        "\n",
        "  lcc_at_end = results[-1]\n",
        "  sim_results.append(lcc_at_end)\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(attack_strengths, sim_results)\n",
        "plt.xlabel('Attack strength')\n",
        "plt.ylabel('Largest connected component')\n",
        "plt.title('Effect of Attack Strength in Cascading Failures')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baz5EtasjkGx"
      },
      "source": [
        "# Part 3. Simulating Computer Virus Spread Across Router Network\n",
        "\n",
        "The flu-like susceptible-infected-susceptible (SIS) is a popular model that allows us to simulate the spread of viruses across networks (graphs). Each node in the SIS model can be in one of two states, infected *I* or susceptible *S*, and at each time step *t*, an infected node has a probability *Œ≤* of infecting each of it's uninfected neighbors. After this, each infected node has a probability *Œ¥* of healing and becoming susceptible again.\n",
        "\n",
        "It‚Äôs been shown there's a direct correlation between the graph's topology as measured through the spectral radius (largest eigenvalue) of the graph, and the virus remaining endemic. The exact relationship between a virus's strength (*s*), birth rate (*Œ≤*), death rate (*Œ¥*) and spectral radius (*Œª1*) is s=Œª1‚ãÖb/d, where a larger *s* means a stronger virus. With just these 3 parameters, we can setup a computer virus simulation.\n",
        "\n",
        "Below, we (1) load the Autonomous systems AS-733 network, which is a graph of routers comprising the internet; and (2) setup the simulation parameters.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrIz_m74jkcv"
      },
      "outputs": [],
      "source": [
        "from graph_tiger.graphs import graph_loader\n",
        "\n",
        "graph = graph_loader('as_733')\n",
        "\n",
        "sis_params = {\n",
        "   'runs': 1,  # number of simulations to run\n",
        "   'steps': 5000,  # number of time steps to run simulation\n",
        "\n",
        "   'model': 'SIS',\n",
        "   'b': 0.00208,  # virus birth rate\n",
        "   'd': 0.01,  # virus death rate\n",
        "   'c': 0.3,  # fraction of the network that starts infected\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eASO8u0Fse8J"
      },
      "source": [
        "Now lets run the simulation and plot the results! In the figure below, we see that without intervention the virus remains endemic on the router network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5EtzM9dmzwQ"
      },
      "outputs": [],
      "source": [
        "from graph_tiger.diffusion import Diffusion\n",
        "\n",
        "diffusion = Diffusion(graph, **sis_params)\n",
        "results = diffusion.run_simulation()\n",
        "\n",
        "diffusion.plot_results(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmotd41csn5N"
      },
      "source": [
        "While we do not have control over the virus strength (*s*), we can maniuplate the underlying toplogy of the router network to make it harder for the virus to spread. The question is, how do we optimally modify the network to reduce the spread of the virus? While a naive solution may be to disconnect the whole network, this isn't very practical since everyone would loose internet access! Instead, we need a strategy that carefully vaccinates a few nodes (routers) against the virus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jlj7TxOueQ4D"
      },
      "source": [
        "### 2. Optimally Vaccinating a Network\n",
        "\n",
        "Now lets compare the efficacy of 4 vaccination strategies when vaccinating only 3 nodes in the network:\n",
        "\n",
        "1. [netshield](https://graph-tiger.readthedocs.io/en/latest/defenses.html#graph_tiger.defenses.get_node_ns) ('ns_node')\n",
        "2. [id_node](https://graph-tiger.readthedocs.io/en/latest/defenses.html#graph_tiger.defenses.get_node_id) ('id_node')\n",
        "2. [rd_node](https://graph-tiger.readthedocs.io/en/latest/defenses.html#graph_tiger.defenses.get_node_rd) ('rd_node')\n",
        "3. [ib_node](https://graph-tiger.readthedocs.io/en/latest/defenses.html#graph_tiger.defenses.get_node_ib) ('ib_node')\n",
        "\n",
        "To implement a defense strategy you just have to modify a few simulation parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOm1GvX9slvx"
      },
      "outputs": [],
      "source": [
        "sis_params.update({\n",
        "    'diffusion': 'min',  # we want to minimize the ability of the virus to propagate,\n",
        "    'method': 'ns_node',  # use the Netshield technique\n",
        "    'k': 15  # vaccinate 5 nodes according the selected strategy\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClLDN5-LhY8i"
      },
      "source": [
        "Does each strategy manage to contain the virus (i.e., less than 1\\% infected population)? Which strategy has the lowest infected population at the end of the simulation? Setup and run each simulation and compare the results to the unvaccinated network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgAk7eEIbcWq"
      },
      "outputs": [],
      "source": [
        "methods = ['ns_node', 'id_node', 'rd_node', 'pr_node']\n",
        "\n",
        "for method in methods:\n",
        "  sis_params['method'] = method\n",
        "\n",
        "  diffusion = Diffusion(graph, **sis_params)\n",
        "  results = diffusion.run_simulation()\n",
        "\n",
        "  print('Percent of network that remains infected at end of simulation using {} vaccination technique is {}%'.format(method, round((results[-1] / len(graph)) * 100, 2)))\n",
        "  diffusion.plot_results(results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
